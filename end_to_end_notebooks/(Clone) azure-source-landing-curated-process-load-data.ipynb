{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8604ebd2-bf9f-4305-8a70-acccad80778a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pyodbc\n",
    "from collections import defaultdict\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48a7b6a4-f5c3-4997-ba55-dc16dee89b55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"pipeline_name\", \"\")\n",
    "dbutils.widgets.text(\"pipeline_run_id\", \"\")\n",
    "dbutils.widgets.text(\"Mode\", \"\")\n",
    "dbutils.widgets.text(\"File_Names\", \"\")\n",
    "dbutils.widgets.text(\"landing_path\", \"\")\n",
    "dbutils.widgets.text(\"curated_path\", \"\")\n",
    "dbutils.widgets.text(\"status\", \"\")\n",
    "dbutils.widgets.text(\"process_mode\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7967dd26-4848-459c-bf09-75a602e6d9f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "pipeline_name = dbutils.widgets.get(\"pipeline_name\").strip()\n",
    "pipeline_run_id = dbutils.widgets.get(\"pipeline_run_id\").strip()\n",
    "mode = dbutils.widgets.get(\"Mode\")\n",
    "File_Names = dbutils.widgets.get(\"File_Names\").strip()\n",
    "landing_path = dbutils.widgets.get(\"landing_path\").strip('/')\n",
    "curated_path = dbutils.widgets.get(\"curated_path\")\n",
    "status=dbutils.widgets.get(\"status\")\n",
    "process_mode=dbutils.widgets.get(\"process_mode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd9bed50-e05b-4837-bbae-0ea05cdb269e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class PipelineLogger:\n",
    "    def __init__(self, pipeline_name, pipeline_run_id):\n",
    "        self.pipeline_name = pipeline_name\n",
    "        self.pipeline_run_id = pipeline_run_id\n",
    " \n",
    "    def _connect(self):\n",
    "        \n",
    "        server = 'ssmssevers.database.windows.net'\n",
    "        database = 'dataa'\n",
    "        username = dbutils.secrets.get(scope='Azr-adf-scope1', key='username')\n",
    "        password = dbutils.secrets.get(scope='Azr-adf-scope1', key='password')\n",
    "        return pyodbc.connect(\n",
    "            f'DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n",
    "        )\n",
    " \n",
    "    def log_start_time(self):\n",
    "        try:\n",
    "            conn = self._connect()\n",
    "            cursor = conn.cursor()\n",
    "            start_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO meta_data.pipeline_logs (pipeline_run_id, pipeline_name, start_time)\n",
    "                VALUES (?, ?, ?)\n",
    "            \"\"\", (self.pipeline_run_id, self.pipeline_name, start_time))\n",
    "            conn.commit()\n",
    "            logger.info(\"Start time logged.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to log start time: {e}\")\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    " \n",
    "    def log_end_time(self, status):\n",
    "        try:\n",
    "            conn = self._connect()\n",
    "            cursor = conn.cursor()\n",
    "            end_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            logger.info(f\"End time: {end_time}, Status: {status}, Run ID: {self.pipeline_run_id}, Pipeline: {self.pipeline_name}\")\n",
    "            cursor.execute(\"\"\"\n",
    "                UPDATE meta_data.pipeline_logs\n",
    "                SET end_time = ?, status = ?\n",
    "                WHERE pipeline_run_id = ? AND pipeline_name = ?\n",
    "            \"\"\", (end_time, status, self.pipeline_run_id, self.pipeline_name))\n",
    "            conn.commit()\n",
    "            logger.info(\"Successfully updated end time and status.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error updating end time/status: {e}\")\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "           \n",
    "\n",
    "    def load_and_transform_table(self,File_Names, landing_path, column_meta_by_table):\n",
    "        logger.info(f\"Processing table: {File_Names}\")\n",
    "        df = spark.read.parquet(landing_path)\n",
    "        mappings = column_meta_by_table.get(File_Names, [])\n",
    " \n",
    "        sql_to_spark_type = {\n",
    "            \"int\": IntegerType(),\n",
    "            \"string\": StringType(),\n",
    "            \"float\": FloatType(),\n",
    "            \"double\": DoubleType(),\n",
    "            \"date\": DateType(),\n",
    "            \"timestamp\": TimestampType(),\n",
    "            \"varchar(500)\": StringType()\n",
    "        }\n",
    " \n",
    "        for col_map in mappings:\n",
    "            src = col_map[\"source_column_name\"]\n",
    "            dst = col_map[\"destination_column_name\"]\n",
    "            dtype = sql_to_spark_type.get(col_map[\"destination_column_data_type\"], StringType())\n",
    " \n",
    "            if src in df.columns:\n",
    "                df = df.withColumn(src, col(src).cast(dtype))\n",
    "                if src != dst:\n",
    "                    df = df.withColumnRenamed(src, dst)\n",
    "            else:\n",
    "                logger.warning(f\"Column not found in the DataFrame: {src}\")\n",
    "        df=df.dropDuplicates()\n",
    "        # print('duplicates:',df)\n",
    " \n",
    "        return df\n",
    " \n",
    "# Main method\n",
    "    def run_dqm_validation(self, File_Names, landing_path, curated_path):\n",
    "        try:\n",
    "            df = spark.read.format(\"parquet\").load(landing_path)\n",
    "            conn = self._connect()\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT source_table_name, source_column_name, destination_column_name, destination_column_data_type\n",
    "                FROM meta_data.column_meta\n",
    "            \"\"\")\n",
    "            rows = cursor.fetchall()\n",
    " \n",
    "            column_meta_by_table = defaultdict(list)\n",
    "            for row in rows:\n",
    "                column_meta_by_table[row.source_table_name].append({\n",
    "                    \"source_column_name\": row.source_column_name,\n",
    "                    \"destination_column_name\": row.destination_column_name,\n",
    "                    \"destination_column_data_type\": row.destination_column_data_type.lower()\n",
    "                })\n",
    " \n",
    "            transformed_df = self.load_and_transform_table(File_Names, landing_path, column_meta_by_table)\n",
    " \n",
    "            output_path = f\"{curated_path}/{File_Names}\"\n",
    "            transformed_df.write.format(\"delta\").mode(mode).option(\"mergeSchema\", \"true\").save(output_path)\n",
    " \n",
    "            logger.info(\"Success\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"DQM Failed: {str(e)}\")\n",
    "\n",
    "\n",
    "    def archive_path(self, landing_path, File_Names):\n",
    "        try: # e.g. container/landing/mkpf\n",
    "            dst_dir = f\"dbfs:/mnt/ETLdata/arc_files/{File_Names}\"  \n",
    "            logger.info(f\"Moving directory {landing_path} to {dst_dir}\")\n",
    " \n",
    "        # Move the whole directory recursively\n",
    "            dbutils.fs.mv(landing_path, dst_dir, recurse=True)\n",
    " \n",
    "            logger.info(f\"Successfully moved {landing_path} to {dst_dir}\")\n",
    " \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to move directory {File_Names}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd3da267-eccc-46df-adc1-6b3935d34bd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    logs = PipelineLogger(pipeline_name, pipeline_run_id)\n",
    " \n",
    "    try:\n",
    "        if process_mode == \"start_time\":\n",
    "            logs.log_start_time()\n",
    "        elif process_mode == \"land_curated\":\n",
    "            logs.run_dqm_validation(File_Names,landing_path, curated_path)\n",
    "        elif process_mode == \"end_time\":\n",
    "            logs.log_end_time(status)\n",
    "        elif process_mode=='ARC_path':\n",
    "            logs.archive_path(landing_path,File_Names)\n",
    "        else:\n",
    "            \n",
    "            print(\" Invalid mode. Use: start, dqm, end.\")\n",
    "    except Exception as ex:\n",
    "       \n",
    "        print(f\" Pipeline failed with error: {ex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5081992c-cc94-4678-add3-ab7d3bf12e7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc57221b-06ed-467b-936c-c6c9b31e0a41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from loguru import logger\n",
    "\n",
    "# logger.info(\"successs\")\n",
    "# logger.error(\"error\")\n",
    "# logger.debug(\"debug\")\n",
    "# logger.warning(\"warning\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8384247217574769,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) azure-source-landing-curated-process-load-data",
   "widgets": {
    "File_Names": {
     "currentValue": "",
     "nuid": "db9a32ca-8902-4dee-a905-12043739a113",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "File_Names",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "File_Names",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "Mode": {
     "currentValue": "",
     "nuid": "212e9d07-e01b-49a4-aff5-c37e4e07bf8b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "Mode",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "Mode",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "curated_path": {
     "currentValue": "",
     "nuid": "7b604a42-8f80-4471-9e81-a12440e32876",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "curated_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "curated_path",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "landing_path": {
     "currentValue": "",
     "nuid": "a8239fc3-29a6-464e-b675-57971c4d0b67",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "landing_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "landing_path",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "mode": {
     "currentValue": "",
     "nuid": "77535472-e886-4740-8ee2-cc0468a09c9c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "mode",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "mode",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "pipeline_name": {
     "currentValue": "",
     "nuid": "43834243-0fab-4266-a47e-511c88f72ecd",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "pipeline_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "pipeline_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "pipeline_run_id": {
     "currentValue": "",
     "nuid": "d3d3b1ba-bcda-4441-9b27-63b42fcd5f04",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "pipeline_run_id",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "pipeline_run_id",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "process_mode": {
     "currentValue": "",
     "nuid": "a4b32402-fa3d-40fa-a4b0-33a0758eec32",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "process_mode",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "process_mode",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "status": {
     "currentValue": "",
     "nuid": "f1d3db89-8e40-4f30-bb52-97f634ea2f65",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "status",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "status",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
